# task and env
# env:
#   env_name:
#   device: "cuda:0"
#   num_envs:

# collector
# collector:
#   num_collectors: 1
#   frames_per_batch: 49152
#   total_frames: 500_000_000

# logger
logger:
  backend: wandb
  project_name: go2_l2t_test
  group_name: null
  exp_name:
  test_interval: 1_000_000
  num_test_episodes: 5
  video: False

# Optim
optim:
  lr: !!float 3e-4
  weight_decay: 0.0
  anneal_lr: True
  device: "cuda:0"

# loss
loss:
  gamma: 0.99
  mini_batch_size:
  epochs: 5
  gae_lambda: 0.95
  clip_epsilon: 0.2
  clip_value: False
  anneal_clip_epsilon: False
  critic_coef: 1.0
  entropy_coef: 0.01
  loss_critic_type: l2

# torch compile
compile:
  compile: False
  compile_mode: default
  cudagraphs: False

# actor and critic
policy:
  num_cells: [512, 256, 128]

value_net:
  num_cells: [512, 256, 128]

# trainer
trainer:
  optim_steps_per_batch: 10
  clip_grad_norm: True
  clip_norm: 0.5
  progress_bar: True
  save_trainer_interval: 10_000
  log_interval: 1000
  save_trainer_file: None
  frame_skip: 1

seed: 42
n_timesteps: !!float 5e8
n_steps: 12
gamma: 0.99
gae_lambda: 0.95
n_epochs: 5
n_batches: 5
ent_coef: 0.01
sde_sample_freq: 4
max_grad_norm: 1.0
vf_coef: 1.0
learning_rate: lin_3e-4
use_sde: False
clip_range: 0.2
device: "cuda:0"
mixture_coeff: 0.2
target_kl: 0.01
policy_kwargs: "dict(
  ortho_init=True,
  activation_fn=nn.ELU,
  net_arch=[512, 256, 128],
  )"
student_policy_kwargs: "dict(
  ortho_init=True,
  activation_fn=nn.ELU,
  net_arch=[512, 256, 128],
  lstm_hidden_size=128,
  )"
